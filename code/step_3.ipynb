{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6047242,"sourceType":"datasetVersion","datasetId":3459373},{"sourceId":9151811,"sourceType":"datasetVersion","datasetId":5528303},{"sourceId":9179156,"sourceType":"datasetVersion","datasetId":5547835},{"sourceId":9179196,"sourceType":"datasetVersion","datasetId":5547856},{"sourceId":9179423,"sourceType":"datasetVersion","datasetId":5548034},{"sourceId":9179489,"sourceType":"datasetVersion","datasetId":5548078},{"sourceId":9496419,"sourceType":"datasetVersion","datasetId":5778734}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### IMPORT LIBRARY","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.cluster import KMeans\nfrom nltk.tokenize import word_tokenize\nimport time\nimport openpyxl\nfrom openpyxl.styles import Alignment, PatternFill\nfrom gensim.models import Word2Vec\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:13:14.165102Z","iopub.execute_input":"2024-09-27T16:13:14.165442Z","iopub.status.idle":"2024-09-27T16:13:33.806732Z","shell.execute_reply.started":"2024-09-27T16:13:14.165405Z","shell.execute_reply":"2024-09-27T16:13:33.805927Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# TF-IDF","metadata":{}},{"cell_type":"code","source":"def preprocess_text_simple(text):\n    if pd.isna(text):\n        return \"\"\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\d+', '', text)\n    return text.strip()\n\ndef load_and_preprocess_course_data(file_path):\n    df = pd.read_csv(file_path)\n    df.drop(columns=['Unnamed: 0', 'Program Type', 'Courses', 'Level', 'Number of Reviews',\n                     'Unique Projects', 'Prequisites', 'What you learn', 'Related Programs',\n                     'Monthly access', '6-Month access', '4-Month access', '3-Month access',\n                     '5-Month access', '2-Month access', 'School', 'Topics related to CRM',\n                     'ExpertTracks', 'FAQs', 'Course Title', 'Course URL',\n                     'Course Short Intro', 'Weekly study', 'Premium course',\n                     \"What's include\", 'Rank', 'Created by', 'Program', 'Number of ratings',\n                     'Price', 'COURSE CATEGORIES'], inplace=True)\n\n    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n    df = df.drop_duplicates(subset=['Title', 'Short Intro'])\n\n    translations = {\n        '计算机科学': 'Computer Science',\n        'Ciencia de Datos': 'Data Science',\n        'Negocios': 'Business',\n        'Ciencias de la Computación': 'Computer Science',\n        'Negócios': 'Business',\n        'データサイエンス': 'Data Science',\n        'Tecnologia da informação': 'Information Technology'\n    }\n    df['Category'] = df['Category'].replace(translations)\n\n    df['Rating'] = df['Rating'].str.replace('stars', '', regex=False)\n    df['Number of viewers'] = df['Number of viewers'].str.replace(r'\\D+', '', regex=True)\n\n    df['combined'] = df['Title'] + ' ' + df['Short Intro'].fillna('') + ' ' + df['Skills'].fillna('') + ' ' + df['Category'].fillna('') + ' ' + df['Sub-Category'].fillna('')\n    df['combined'] = df['combined'].apply(preprocess_text_simple)\n\n    fill_columns = ['Instructors', 'Duration', 'Site', 'Course Type', 'Language', 'Subtitle Languages', 'Category', 'Sub-Category', 'Short Intro', 'Skills']\n    for col in fill_columns:\n        df[col] = df[col].fillna('Unknown')\n\n    df['Number of viewers'] = pd.to_numeric(df['Number of viewers'], errors='coerce').fillna(0)\n    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce').fillna(0)\n\n    return df\n\ndef recommend(user_input, df, vectorizer, tfidf_matrix):\n    user_input_processed = preprocess_text_simple(user_input)\n    user_tfidf = vectorizer.transform([user_input_processed])\n\n    cosine_similarities = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n\n    top_course_indices = cosine_similarities.argsort()[::-1]\n\n    recommendations = df.iloc[top_course_indices].copy()\n    recommendations['cosine_similarity'] = cosine_similarities[top_course_indices]\n\n    return recommendations\n\ndef process_test_cases_and_save(test_cases_file, course_data_file, output_file):\n    df = load_and_preprocess_course_data(course_data_file)\n\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(df['combined'])\n\n    test_cases_df = pd.read_csv(test_cases_file)\n\n    wb = openpyxl.Workbook()\n    ws = wb.active\n    ws.title = \"Course Recommendations\"\n\n    headers = ['No', 'User Preferences', 'Recommended Courses', 'Scores']\n    for col, header in enumerate(headers, start=1):\n        ws.cell(row=1, column=col, value=header)\n\n    row_counter = 2\n    for idx, row in test_cases_df.iterrows():\n        user_input = row['Case']\n\n        recommendations = recommend(user_input, df, vectorizer, tfidf_matrix)\n\n        percentile_threshold = 95\n        threshold_value = np.percentile(recommendations['cosine_similarity'], percentile_threshold)\n        recommendations_final = recommendations[recommendations['cosine_similarity'] >= threshold_value]\n\n        # Limit the output to 5 top recommendations\n        rec_titles = recommendations_final['Title'].tolist()[:5]\n        scores = recommendations_final['cosine_similarity'].round(4).tolist()[:5]\n\n        ws.cell(row=row_counter, column=1, value=idx + 1)\n        ws.cell(row=row_counter, column=2, value=user_input)\n\n        for rec, score in zip(rec_titles, scores):\n            ws.cell(row=row_counter, column=3, value=rec)\n            ws.cell(row=row_counter, column=4, value=score)\n            row_counter += 1\n\n        # Pad empty rows if fewer than 5 recommendations are available\n        for _ in range(5 - len(rec_titles)):\n            ws.cell(row=row_counter, column=3, value=\"\")\n            ws.cell(row=row_counter, column=4, value=\"\")\n            row_counter += 1\n\n    for row in range(2, ws.max_row, 5):  # Adjust for 5 recommendations per case\n        ws.merge_cells(start_row=row, start_column=1, end_row=row+4, end_column=1)\n        ws.merge_cells(start_row=row, start_column=2, end_row=row+4, end_column=2)\n\n    header_fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n    for cell in ws[1]:\n        cell.fill = header_fill\n        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n\n    for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n        for cell in row:\n            cell.alignment = Alignment(vertical='top', wrap_text=True)\n\n    ws.column_dimensions['A'].width = 5\n    ws.column_dimensions['B'].width = 50\n    ws.column_dimensions['C'].width = 50\n    ws.column_dimensions['D'].width = 15\n\n    wb.save(output_file)\n    print(f\"Course recommendations saved to '{output_file}'\")\n\nif __name__ == \"__main__\":\n    test_cases_file = '/kaggle/input/dataset/test_case_course.csv'\n    course_data_file = '/kaggle/input/dataset/Online_Courses.csv'\n    output_file = 'course_recommendations_tfidf.xlsx'\n\n    process_test_cases_and_save(test_cases_file, course_data_file, output_file)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T16:14:09.642357Z","iopub.execute_input":"2024-09-27T16:14:09.643008Z","iopub.status.idle":"2024-09-27T16:14:11.035480Z","shell.execute_reply.started":"2024-09-27T16:14:09.642967Z","shell.execute_reply":"2024-09-27T16:14:11.034598Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1005895275.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n","output_type":"stream"},{"name":"stdout","text":"Course recommendations saved to 'course_recommendations_tfidf.xlsx'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# WORD2VEC","metadata":{}},{"cell_type":"code","source":"def preprocess_text_simple(text):\n    if pd.isna(text):\n        return \"\"\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\d+', '', text)\n    return text.strip()\n\ndef load_and_preprocess_course_data(file_path):\n    df = pd.read_csv(file_path)\n    df.drop(columns=['Unnamed: 0','Program Type', 'Courses', 'Level', 'Number of Reviews',\n           'Unique Projects', 'Prequisites', 'What you learn', 'Related Programs',\n           'Monthly access', '6-Month access', '4-Month access', '3-Month access',\n           '5-Month access', '2-Month access', 'School', 'Topics related to CRM',\n           'ExpertTracks', 'FAQs', 'Course Title', 'Course URL',\n           'Course Short Intro', 'Weekly study', 'Premium course',\n           \"What's include\", 'Rank', 'Created by', 'Program', 'Number of ratings',\n           'Price', 'COURSE CATEGORIES'], inplace=True)\n    \n    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n    df = df.drop_duplicates(subset=['Title', 'Short Intro'])\n    \n    translations = {\n        '计算机科学': 'Computer Science',\n        'Ciencia de Datos': 'Data Science',\n        'Negocios': 'Business',\n        'Ciencias de la Computación': 'Computer Science',\n        'Negócios': 'Business',\n        'データサイエンス': 'Data Science',\n        'Tecnologia da informação': 'Information Technology'\n    }\n    df['Category'] = df['Category'].replace(translations)\n    \n    df['Rating'] = df['Rating'].str.replace('stars', '', regex=False)\n    df['Number of viewers'] = df['Number of viewers'].str.replace(r'\\D+', '', regex=True)\n    \n    df['combined'] = df['Title'] + ' ' + df['Short Intro'].fillna('') + ' ' + df['Skills'].fillna('') + ' ' + df['Category'].fillna('') + ' ' + df['Sub-Category'].fillna('')\n    df['combined'] = df['combined'].apply(preprocess_text_simple)\n    \n    keywords = ['Participant', 'Designed', 'Learners', 'prior', 'experience']\n    df['Subtitle Languages'] = df['Subtitle Languages'].apply(lambda x: np.nan if any(keyword in str(x) for keyword in keywords) else x)\n    \n    fill_columns = ['Instructors', 'Duration', 'Site', 'Course Type', 'Language', 'Subtitle Languages', 'Category', 'Sub-Category', 'Short Intro', 'Skills']\n    for col in fill_columns:\n        df[col] = df[col].fillna('Unknown')\n    \n    df['Number of viewers'] = pd.to_numeric(df['Number of viewers'], errors='coerce').fillna(0).astype(int)\n    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce').fillna(0)\n    \n    df['Tokenized'] = df['combined'].apply(word_tokenize)\n    \n    return df\n\ndef train_word2vec(df):\n    model = Word2Vec(sentences=df['Tokenized'], vector_size=100, window=5, min_count=1, workers=4)\n    return model\n\ndef get_document_vector(doc, model):\n    words = word_tokenize(doc)\n    word_vectors = [model.wv[word] for word in words if word in model.wv]\n    if len(word_vectors) == 0:\n        return np.zeros(model.vector_size)\n    return np.mean(word_vectors, axis=0)\n\ndef vectorize_text(df, model):\n    doc_vectors = np.array([get_document_vector(doc, model) for doc in df['combined']])\n    return doc_vectors\n\ndef imdb_score(df, q=0.95):\n    df = df.copy()\n    m = df['Number of viewers'].quantile(q)\n    c = (df['Rating'] * df['Number of viewers']).sum() / df['Number of viewers'].sum()\n    df[\"score\"] = df.apply(lambda x: (x.Rating * x['Number of viewers'] + c*m) / (x['Number of viewers'] + m), axis=1)\n    return df\n\ndef recommend_course(user_input, df, model, doc_vectors):\n    user_input_processed = preprocess_text_simple(user_input)\n    user_vector = get_document_vector(user_input_processed, model)\n    \n    cosine_similarities = cosine_similarity([user_vector], doc_vectors).flatten()\n    \n    df_temp = df.copy()\n    df_temp['cosine_similarity'] = cosine_similarities\n    \n    percentile_threshold = 95\n    threshold_value = np.percentile(df_temp['cosine_similarity'], percentile_threshold)\n    stage1 = df_temp[df_temp['cosine_similarity'] >= threshold_value]\n    \n    stage2 = imdb_score(stage1)\n    stage2['score'] = (stage2['score'] - stage2['score'].min()) / (stage2['score'].max() - stage2['score'].min())\n    stage2['cosine_similarity'] = (stage2['cosine_similarity'] - stage2['cosine_similarity'].min()) / (stage2['cosine_similarity'].max() - stage2['cosine_similarity'].min())\n    \n    stage2['Final'] = 0.5 * stage2['cosine_similarity'] + 0.5 * stage2['score']\n    stage2 = stage2.sort_values(by='Final', ascending=False)\n    \n    threshold_value = np.percentile(stage2['Final'], percentile_threshold)\n    recommendations_final = stage2[stage2['Final'] >= threshold_value]\n    \n    return recommendations_final\n\ndef process_test_cases_and_save(test_cases_file, course_data_file, output_file, model, doc_vectors):\n    test_cases_df = pd.read_csv(test_cases_file)\n    df = load_and_preprocess_course_data(course_data_file)\n\n    wb = openpyxl.Workbook()\n    ws = wb.active\n    ws.title = \"Course Recommendations\"\n\n    headers = ['No', 'User Preferences', 'Recommended Courses', 'Scores']\n    for col, header in enumerate(headers, start=1):\n        ws.cell(row=1, column=col, value=header)\n\n    row_counter = 2\n    for idx, row in test_cases_df.iterrows():\n        user_input = row['Case']\n        \n        recommendations = recommend_course(user_input, df, model, doc_vectors)\n        \n        if not recommendations.empty:\n            rec_titles = recommendations['Title'].tolist()[:10]\n            scores = recommendations['Final'].round(4).tolist()[:10]\n        else:\n            rec_titles = [\"No relevant courses found\"]\n            scores = [\"N/A\"]\n\n        ws.cell(row=row_counter, column=1, value=idx + 1)\n        ws.cell(row=row_counter, column=2, value=user_input)\n        \n        for rec, score in zip(rec_titles, scores):\n            ws.cell(row=row_counter, column=3, value=rec)\n            ws.cell(row=row_counter, column=4, value=score)\n            row_counter += 1\n\n        for _ in range(10 - len(rec_titles)):\n            ws.cell(row=row_counter, column=3, value=\"\")\n            ws.cell(row=row_counter, column=4, value=\"\")\n            row_counter += 1\n\n    for row in range(2, ws.max_row, 10):\n        ws.merge_cells(start_row=row, start_column=1, end_row=row+9, end_column=1)\n        ws.merge_cells(start_row=row, start_column=2, end_row=row+9, end_column=2)\n\n    header_fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n    for cell in ws[1]:\n        cell.fill = header_fill\n        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n\n    for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n        for cell in row:\n            cell.alignment = Alignment(vertical='top', wrap_text=True)\n\n    ws.column_dimensions['A'].width = 5\n    ws.column_dimensions['B'].width = 50\n    ws.column_dimensions['C'].width = 50\n    ws.column_dimensions['D'].width = 15\n\n    wb.save(output_file)\n    print(f\"Course recommendations saved to '{output_file}'\")\n\nif __name__ == \"__main__\":\n    test_cases_file = '/kaggle/input/benerdong/Updated_User_Preferences_Comma_Delimited.csv'\n    course_data_file = '/kaggle/input/online-courses/Online_Courses.csv'\n    output_file = 'course_recommendations_word2vec.xlsx'\n    \n    df = load_and_preprocess_course_data(course_data_file)\n    word2vec_model = train_word2vec(df)\n    doc_vectors = vectorize_text(df, word2vec_model)\n    \n    process_test_cases_and_save(test_cases_file, course_data_file, output_file, word2vec_model, doc_vectors)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\ndef preprocess_text_simple(text):\n    if pd.isna(text):\n        return \"\"\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\d+', '', text)\n    return text.strip()\n\ndef load_and_preprocess_course_data(file_path):\n    df = pd.read_csv(file_path)\n    df.drop(columns=['Unnamed: 0','Program Type', 'Courses', 'Level', 'Number of Reviews',\n           'Unique Projects', 'Prequisites', 'What you learn', 'Related Programs',\n           'Monthly access', '6-Month access', '4-Month access', '3-Month access',\n           '5-Month access', '2-Month access', 'School', 'Topics related to CRM',\n           'ExpertTracks', 'FAQs', 'Course Title', 'Course URL',\n           'Course Short Intro', 'Weekly study', 'Premium course',\n           \"What's include\", 'Rank', 'Created by', 'Program', 'Number of ratings',\n           'Price', 'COURSE CATEGORIES'], inplace=True)\n    \n    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n    df = df.drop_duplicates(subset=['Title', 'Short Intro'])\n    \n    translations = {\n        '计算机科学': 'Computer Science',\n        'Ciencia de Datos': 'Data Science',\n        'Negocios': 'Business',\n        'Ciencias de la Computación': 'Computer Science',\n        'Negócios': 'Business',\n        'データサイエンス': 'Data Science',\n        'Tecnologia da informação': 'Information Technology'\n    }\n    df['Category'] = df['Category'].replace(translations)\n    \n    df['Rating'] = df['Rating'].str.replace('stars', '', regex=False)\n    df['Number of viewers'] = df['Number of viewers'].str.replace(r'\\D+', '', regex=True)\n    \n    df['combined'] = df['Title'] + ' ' + df['Short Intro'].fillna('') + ' ' + df['Skills'].fillna('') + ' ' + df['Category'].fillna('') + ' ' + df['Sub-Category'].fillna('')\n    df['combined'] = df['combined'].apply(preprocess_text_simple)\n    \n    keywords = ['Participant', 'Designed', 'Learners', 'prior', 'experience']\n    df['Subtitle Languages'] = df['Subtitle Languages'].apply(lambda x: np.nan if any(keyword in str(x) for keyword in keywords) else x)\n    \n    fill_columns = ['Instructors', 'Duration', 'Site', 'Course Type', 'Language', 'Subtitle Languages', 'Category', 'Sub-Category', 'Short Intro', 'Skills']\n    for col in fill_columns:\n        df[col] = df[col].fillna('Unknown')\n    \n    df['Number of viewers'] = pd.to_numeric(df['Number of viewers'], errors='coerce').fillna(0).astype(int)\n    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce').fillna(0)\n    \n    return df\n\ndef get_bert_embedding(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n\ndef vectorize_text(df):\n    doc_vectors = []\n    for doc in tqdm(df['combined'], desc=\"Vectorizing documents\"):\n        doc_vectors.append(get_bert_embedding(doc))\n    return np.array(doc_vectors)\n\ndef imdb_score(df, q=0.95):\n    df = df.copy()\n    m = df['Number of viewers'].quantile(q)\n    c = (df['Rating'] * df['Number of viewers']).sum() / df['Number of viewers'].sum()\n    df[\"score\"] = df.apply(lambda x: (x.Rating * x['Number of viewers'] + c*m) / (x['Number of viewers'] + m), axis=1)\n    return df\n\ndef recommend_course(user_input, df, doc_vectors):\n    user_input_processed = preprocess_text_simple(user_input)\n    user_vector = get_bert_embedding(user_input_processed)\n    \n    cosine_similarities = cosine_similarity([user_vector], doc_vectors).flatten()\n    \n    df_temp = df.copy()\n    df_temp['cosine_similarity'] = cosine_similarities\n    \n    percentile_threshold = 95\n    threshold_value = np.percentile(df_temp['cosine_similarity'], percentile_threshold)\n    stage1 = df_temp[df_temp['cosine_similarity'] >= threshold_value]\n    \n    stage2 = imdb_score(stage1)\n    stage2['score'] = (stage2['score'] - stage2['score'].min()) / (stage2['score'].max() - stage2['score'].min())\n    stage2['cosine_similarity'] = (stage2['cosine_similarity'] - stage2['cosine_similarity'].min()) / (stage2['cosine_similarity'].max() - stage2['cosine_similarity'].min())\n    \n    stage2['Final'] = 0.5 * stage2['cosine_similarity'] + 0.5 * stage2['score']\n    stage2 = stage2.sort_values(by='Final', ascending=False)\n    \n    threshold_value = np.percentile(stage2['Final'], percentile_threshold)\n    recommendations_final = stage2[stage2['Final'] >= threshold_value]\n    \n    return recommendations_final\n\ndef process_test_cases_and_save(test_cases_file, course_data_file, output_file, doc_vectors):\n    test_cases_df = pd.read_csv(test_cases_file)\n    df = load_and_preprocess_course_data(course_data_file)\n\n    wb = openpyxl.Workbook()\n    ws = wb.active\n    ws.title = \"Course Recommendations\"\n\n    headers = ['No', 'User Preferences', 'Recommended Courses', 'Scores']\n    for col, header in enumerate(headers, start=1):\n        ws.cell(row=1, column=col, value=header)\n\n    row_counter = 2\n    for idx, row in tqdm(test_cases_df.iterrows(), total=len(test_cases_df), desc=\"Processing test cases\"):\n        user_input = row['Case']\n        \n        recommendations = recommend_course(user_input, df, doc_vectors)\n        \n        if not recommendations.empty:\n            rec_titles = recommendations['Title'].tolist()[:10]\n            scores = recommendations['Final'].round(4).tolist()[:10]\n        else:\n            rec_titles = [\"No relevant courses found\"]\n            scores = [\"N/A\"]\n\n        ws.cell(row=row_counter, column=1, value=idx + 1)\n        ws.cell(row=row_counter, column=2, value=user_input)\n        \n        for rec, score in zip(rec_titles, scores):\n            ws.cell(row=row_counter, column=3, value=rec)\n            ws.cell(row=row_counter, column=4, value=score)\n            row_counter += 1\n\n        for _ in range(10 - len(rec_titles)):\n            ws.cell(row=row_counter, column=3, value=\"\")\n            ws.cell(row=row_counter, column=4, value=\"\")\n            row_counter += 1\n\n    for row in range(2, ws.max_row, 10):\n        ws.merge_cells(start_row=row, start_column=1, end_row=row+9, end_column=1)\n        ws.merge_cells(start_row=row, start_column=2, end_row=row+9, end_column=2)\n\n    header_fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n    for cell in ws[1]:\n        cell.fill = header_fill\n        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n\n    for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n        for cell in row:\n            cell.alignment = Alignment(vertical='top', wrap_text=True)\n\n    ws.column_dimensions['A'].width = 5\n    ws.column_dimensions['B'].width = 50\n    ws.column_dimensions['C'].width = 50\n    ws.column_dimensions['D'].width = 15\n\n    wb.save(output_file)\n    print(f\"Course recommendations saved to '{output_file}'\")\n\nif __name__ == \"__main__\":\n    test_cases_file = '/kaggle/input/benerdong/Updated_User_Preferences_Comma_Delimited.csv'\n    course_data_file = '/kaggle/input/online-courses/Online_Courses.csv'\n    output_file = 'course_recommendations_bert.xlsx'\n    \n    df = load_and_preprocess_course_data(course_data_file)\n    doc_vectors = vectorize_text(df)\n    \n    process_test_cases_and_save(test_cases_file, course_data_file, output_file, doc_vectors)","metadata":{"execution":{"iopub.execute_input":"2024-08-15T13:29:02.955193Z","iopub.status.busy":"2024-08-15T13:29:02.954840Z","iopub.status.idle":"2024-08-15T13:37:54.245009Z","shell.execute_reply":"2024-08-15T13:37:54.244047Z","shell.execute_reply.started":"2024-08-15T13:29:02.955161Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_414/2973497617.py:35: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n\n  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\nVectorizing documents: 100%|██████████| 4988/4988 [08:36<00:00,  9.67it/s]\n\n/tmp/ipykernel_414/2973497617.py:35: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n\n  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\nProcessing test cases: 100%|██████████| 50/50 [00:09<00:00,  5.06it/s]\n"},{"name":"stdout","output_type":"stream","text":"Course recommendations saved to 'course_recommendations_bert.xlsx'\n"}]}]}